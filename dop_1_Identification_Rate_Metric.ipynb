{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c77dm4e-bQyn"
      },
      "source": [
        "## Identification Rate Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMRcQD7PbVQ-"
      },
      "source": [
        "При обучении модели для распознавания лиц с помощью CE (кросс-энтропии) мы можем считать метрику accuracy как индикатор того, насколько хорошо наша модель работает. Но у accuracy тут есть недостаток: она не сможет померить, насколько хорошо наша модель работает на лицах людей, которых нет в обучающей выборке.  \n",
        "\n",
        "Чтобы это исправить, придумали новую метрику: **identification rate**. Вот как она работает:\n",
        "\n",
        "Создадим два набора изображений лиц: query и distractors. Никакие лица из этих наборов не должны содержаться в обучающем и валидационном датасете.\n",
        "\n",
        "1. посчитаем косинусные расстояния между лицами, соответствующими одним и тем же людям из query части. Например, пусть одному человеку соответствуют три фото в query: 01.jpg, 02.jpg, 03.jpg. Тогда считаем три косинусных расстояния между всеми тремя парами из этих фото.\n",
        "2. посчитаем косинусные расстояния между лицами, соответствующими разным людям из query части.\n",
        "3. посчитаем косинусные расстояния между всеми парами лиц из query и distractors. Т.е. пара — это (лицо из query, лицо из distractors). Всего получится |query|*|distractors| пар.\n",
        "4. Сложим количества пар, полученных на 2 и 3 шагах. Это количество false пар.\n",
        "5. Зафиксируем **FPR** (false positive rate). Пусть, например, будет 0.01. FPR, умноженный на количество false пар из шага 4 — это разрешенное количество false positives, которые мы разрешаем нашей модели. Обозначим это количество через N.\n",
        "6. Отсортируем все значения косинусных расстояний false пар. N — ое по счету значение расстояния зафиксируем как **пороговое расстояние**.\n",
        "7. Посчитаем количество positive пар с шага 1, которые имеют косинусное расстояние меньше, чем пороговое расстояние. Поделим это количество на общее количество positive пар с шага 1. Это будет TPR (true positive rate) — итоговое значение нашей метрики.\n",
        "\n",
        "Такая метрика обычно обозначается как TPR@FPR=0.01. FPR может быть разным. Приразных FPR будет получаться разное TPR.\n",
        "\n",
        "Смысл этой метрики в том, что мы фиксируем вероятность ошибки вида false positive, т.е. когда \"сеть сказала, что это один и тот же человек, но это не так\", считаем порог косинусного расстояния для этого значения ошибки, потом берем все positive пары и смотрим, у скольких из них расстояние меньше этого порога. Т.е. насколько точно наша сеть ищет похожие лица при заданной вероятности ошибки вида false positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puAg1BoLMUsl"
      },
      "source": [
        "**Для подсчета метрик, то вам нужно разбить данные на query и distractors самим.**\n",
        "\n",
        "Делается это примерно так:\n",
        "- Выбраете несколько id, которые не использовались при тренировке моделей, и помещаете их в query set;\n",
        "- Выбираете несколько id, которые не использовались при тренировке моделей и не входят в query, и помещаете их в distractors set. Обычно distractors set должен быть сильно больше, чем query set.\n",
        "- Обрабатываете картинки из query и distractors тем же способом, что картинки для обучения сети.\n",
        "\n",
        "\n",
        "Обратите внимание, что если картинок в query и distractors очень много, то полученных пар картинок в пунктах 1-2-3 алгоритма подсчета TPR@FPR будет очень-очень много. Чтобы код подсчета работал быстрее, ограничивайте размеры этих датасетов. Контролируйте, сколько значений расстояний вы считаете.\n",
        "\n",
        "Ниже дан шаблон кода для реализации FPR@TPR метрики и ячейки с тестами. Тесты проверяют, что ваш код в ячейках написан правильно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gud62bxyQ9jR"
      },
      "source": [
        "## План заданий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpUHjvrfRDWw"
      },
      "source": [
        "* Правильно разбить датасет на query и distractors\n",
        "* Реализовать метрику и пройти все тесты\n",
        "* Подгрузить все модели, обученные на разных лоссах и сравнить их метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')      \n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "    \n",
        "from models import get_recognition_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Разбить датасет загрузить данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query IDs: 200, Query Images: 5572\n",
            "Distractor IDs: 1000, Distractor Images: 27865\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "TRAIN_IDS_PATH = 'data/celeba_aligned_top_500'\n",
        "DATA_ROOT = 'data/celeba_aligned_top_2000'\n",
        "N_QUERY = 200\n",
        "N_DISTRACTORS = 1000\n",
        "\n",
        "train_ids = set(os.listdir(TRAIN_IDS_PATH))\n",
        "all_person_ids = os.listdir(DATA_ROOT)\n",
        "\n",
        "test_ids_pool = [pid for pid in all_person_ids if pid not in train_ids]\n",
        "random.shuffle(test_ids_pool)\n",
        "\n",
        "query_ids = set(test_ids_pool[:N_QUERY])\n",
        "distractor_ids = set(test_ids_pool[N_QUERY : N_QUERY + N_DISTRACTORS])\n",
        "\n",
        "query_dict_temp = defaultdict(list)\n",
        "distractors_img_names = []\n",
        "\n",
        "for person_id in os.listdir(DATA_ROOT):\n",
        "    if person_id in query_ids:\n",
        "        for img_file in os.listdir(os.path.join(DATA_ROOT, person_id)):\n",
        "            relative_path = os.path.join(DATA_ROOT, person_id, img_file)\n",
        "            query_dict_temp[person_id].append(relative_path)\n",
        "    elif person_id in distractor_ids:\n",
        "        for img_file in os.listdir(os.path.join(DATA_ROOT, person_id)):\n",
        "            relative_path = os.path.join(DATA_ROOT, person_id, img_file)\n",
        "            distractors_img_names.append(relative_path)\n",
        "\n",
        "query_dict = {pid: names for pid, names in query_dict_temp.items() if len(names) > 1}\n",
        "query_img_names = [name for names in query_dict.values() for name in names]\n",
        "\n",
        "print(f\"Query IDs: {len(query_dict)}, Query Images: {len(query_img_names)}\")\n",
        "print(f\"Distractor IDs: {len(distractor_ids)}, Distractor Images: {len(distractors_img_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_recognition_model()\n",
        "model.fc = nn.Identity()\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcwpIx3UAw-z"
      },
      "source": [
        "## Шаблон кода для Identificaton rate metric (TPR@FPR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b1_DNpTC_lpQ"
      },
      "outputs": [],
      "source": [
        "def compute_embeddings(model, images_list):\n",
        "  '''\n",
        "  compute embeddings from the trained model for list of images.\n",
        "  params:\n",
        "    model: trained nn model that takes images and outputs embeddings\n",
        "    images_list: list of images paths to compute embeddings for\n",
        "  output:\n",
        "    list: list of model embeddings. Each embedding corresponds to images\n",
        "          names from images_list\n",
        "  '''\n",
        "  model.eval()\n",
        "  embeddings = []\n",
        "  with torch.no_grad(): \n",
        "    for img in images_list:\n",
        "      img = Image.open(img)\n",
        "      tensor = transform(img).unsqueeze(0).to(device)\n",
        "      embedding = model(tensor)\n",
        "      embeddings.append(embedding.cpu().numpy())\n",
        "  return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_cosine(emb1, emb2):\n",
        "    # emb1 = emb1.flatten()\n",
        "    # emb2 = emb2.flatten()\n",
        "    # emb1 = emb1[0]\n",
        "    # emb2 = emb2[0]\n",
        "    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AD2LXD87_jmR"
      },
      "outputs": [],
      "source": [
        "query_embeddings = compute_embeddings(model, query_img_names)\n",
        "distractors_embeddings = compute_embeddings(model, distractors_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ksOfuF_C_fWI"
      },
      "outputs": [],
      "source": [
        "def compute_cosine_query_pos(query_dict, query_img_names, query_embeddings):\n",
        "  '''\n",
        "  compute cosine similarities between positive pairs from query (stage 1)\n",
        "  params:\n",
        "    query_dict: dict {class: [image_name_1, image_name_2, ...]}. Key: class in\n",
        "                the dataset. Value: images corresponding to that class\n",
        "    query_img_names: list of images names\n",
        "    query_embeddings: list of embeddings corresponding to query_img_names\n",
        "  output:\n",
        "    list of floats: similarities between embeddings corresponding\n",
        "                    to the same people from query list\n",
        "  '''\n",
        "  img_to_emb = {name: emb for name, emb in zip(query_img_names, query_embeddings)}\n",
        "  pos_similarities = []\n",
        "  for person_id, list_of_his_images in query_dict.items():\n",
        "      for img1_path, img2_path in combinations(list_of_his_images, 2):\n",
        "          emb1 = img_to_emb[img1_path]\n",
        "          emb2 = img_to_emb[img2_path]\n",
        "          pos_similarities.append(compute_cosine(emb1, emb2))\n",
        "  return pos_similarities\n",
        "\n",
        "def compute_cosine_query_neg(query_dict, query_img_names, query_embeddings):\n",
        "  '''\n",
        "  compute cosine similarities between negative pairs from query (stage 2)\n",
        "  params:\n",
        "    query_dict: dict {class: [image_name_1, image_name_2, ...]}. Key: class in\n",
        "                the dataset. Value: images corresponding to that class\n",
        "    query_img_names: list of images names\n",
        "    query_embeddings: list of embeddings corresponding to query_img_names\n",
        "  output:\n",
        "    list of floats: similarities between embeddings corresponding\n",
        "                    to different people from query list\n",
        "  '''\n",
        "  img_to_emb = {name: emb for name, emb in zip(query_img_names, query_embeddings)}\n",
        "  neg_similarities = []\n",
        "  person_ids = list(query_dict.keys())\n",
        "  for id1, id2 in combinations(person_ids, 2):\n",
        "      for img1_path in query_dict[id1]:\n",
        "          for img2_path in query_dict[id2]:\n",
        "              emb1 = img_to_emb[img1_path]\n",
        "              emb2 = img_to_emb[img2_path]\n",
        "              similarity = compute_cosine(emb1, emb2)\n",
        "              neg_similarities.append(similarity)\n",
        "  return neg_similarities\n",
        "\n",
        "def compute_cosine_query_distractors(query_embeddings, distractors_embeddings):\n",
        "  '''\n",
        "  compute cosine similarities between negative pairs from query and distractors\n",
        "  (stage 3)\n",
        "  params:\n",
        "    query_embeddings: list of embeddings corresponding to query_img_names\n",
        "    distractors_embeddings: list of embeddings corresponding to distractors_img_names\n",
        "  output:\n",
        "    list of floats: similarities between pairs of people (q, d), where q is\n",
        "                    embedding corresponding to photo from query, d —\n",
        "                    embedding corresponding to photo from distractors\n",
        "  '''\n",
        "  cross_similarities = []\n",
        "  for q_emb in query_embeddings:\n",
        "      for d_emb in distractors_embeddings:\n",
        "          similarity = compute_cosine(q_emb, d_emb) \n",
        "          cross_similarities.append(similarity)\n",
        "  return cross_similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sL5eieLz_a6T"
      },
      "outputs": [],
      "source": [
        "cosine_query_pos = compute_cosine_query_pos(query_dict, query_img_names,\n",
        "                                            query_embeddings)\n",
        "cosine_query_neg = compute_cosine_query_neg(query_dict, query_img_names,\n",
        "                                            query_embeddings)\n",
        "cosine_query_distractors = compute_cosine_query_distractors(query_embeddings,\n",
        "                                                            distractors_embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYSlzv5s_0-F"
      },
      "source": [
        "Ячейка ниже проверяет, что код работает верно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OEFojrOY_44r"
      },
      "outputs": [],
      "source": [
        "test_query_dict = {\n",
        "    2876: ['1.jpg', '2.jpg', '3.jpg'],\n",
        "    5674: ['5.jpg'],\n",
        "    864:  ['9.jpg', '10.jpg'],\n",
        "}\n",
        "test_query_img_names = ['1.jpg', '2.jpg', '3.jpg', '5.jpg', '9.jpg', '10.jpg']\n",
        "test_query_embeddings = [\n",
        "                    [1.56, 6.45,  -7.68],\n",
        "                    [-1.1 , 6.11,  -3.0],\n",
        "                    [-0.06,-0.98,-1.29],\n",
        "                    [8.56, 1.45,  1.11],\n",
        "                    [0.7,  1.1,   -7.56],\n",
        "                    [0.05, 0.9,   -2.56],\n",
        "]\n",
        "\n",
        "test_distractors_img_names = ['11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg']\n",
        "\n",
        "test_distractors_embeddings = [\n",
        "                    [0.12, -3.23, -5.55],\n",
        "                    [-1,   -0.01, 1.22],\n",
        "                    [0.06, -0.23, 1.34],\n",
        "                    [-6.6, 1.45,  -1.45],\n",
        "                    [0.89,  1.98, 1.45],\n",
        "]\n",
        "\n",
        "test_cosine_query_pos = compute_cosine_query_pos(test_query_dict, test_query_img_names,\n",
        "                                            test_query_embeddings)\n",
        "test_cosine_query_neg = compute_cosine_query_neg(test_query_dict, test_query_img_names,\n",
        "                                            test_query_embeddings)\n",
        "test_cosine_query_distractors = compute_cosine_query_distractors(test_query_embeddings,\n",
        "                                                            test_distractors_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIyWXmE_5tS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8678237233650096, 0.21226104378511595, -0.1835586697749618, 0.9787437979250561]\n"
          ]
        }
      ],
      "source": [
        "true_cosine_query_pos = [0.8678237233650096, 0.21226104378511604,\n",
        "                         -0.18355866977496182, 0.9787437979250561]\n",
        "# print(test_cosine_query_pos)\n",
        "assert np.allclose(sorted(test_cosine_query_pos), sorted(true_cosine_query_pos)), \\\n",
        "      \"A mistake in compute_cosine_query_pos function\"\n",
        "\n",
        "true_cosine_query_neg = [0.15963231223161822, 0.8507997093616965, 0.9272761484302097,\n",
        "                         -0.0643994061127092, 0.5412660901220571, 0.701307100338029,\n",
        "                         -0.2372575528216902, 0.6941032794522218, 0.549425446066643,\n",
        "                         -0.011982733001947084, -0.0466679194884999]\n",
        "assert np.allclose(sorted(test_cosine_query_neg), sorted(true_cosine_query_neg)), \\\n",
        "      \"A mistake in compute_cosine_query_neg function\"\n",
        "\n",
        "true_cosine_query_distractors = [0.3371426578637511, -0.6866465610863652, -0.8456563512871669,\n",
        "                                 0.14530087113136106, 0.11410510307646118, -0.07265097629002357,\n",
        "                                 -0.24097699660707042,-0.5851992679925766, 0.4295494455718534,\n",
        "                                 0.37604478596058194, 0.9909483738948858, -0.5881093317868022,\n",
        "                                 -0.6829712976642919, 0.07546364489032083, -0.9130970963915521,\n",
        "                                 -0.17463101988684684, -0.5229363015558941, 0.1399896725311533,\n",
        "                                 -0.9258034013399499, 0.5295114163723346, 0.7811585442749943,\n",
        "                                 -0.8208760031249596, -0.9905139680301821, 0.14969764653247228,\n",
        "                                 -0.40749654525418444, 0.648660814944824, -0.7432584300096284,\n",
        "                                 -0.9839696492435877, 0.2498741082804709, -0.2661183373780491]\n",
        "assert np.allclose(sorted(test_cosine_query_distractors), sorted(true_cosine_query_distractors)), \\\n",
        "      \"A mistake in compute_cosine_query_distractors function\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgfGS4PzBXog"
      },
      "source": [
        "И, наконец, финальная функция, которая считает IR metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rJJ0ef6t_VLJ"
      },
      "outputs": [],
      "source": [
        "def compute_ir(cosine_query_pos, cosine_query_neg, cosine_query_distractors,\n",
        "               fpr=0.1):\n",
        "  '''\n",
        "  compute identification rate using precomputer cosine similarities between pairs\n",
        "  at given fpr\n",
        "  params:\n",
        "    cosine_query_pos: cosine similarities between positive pairs from query\n",
        "    cosine_query_neg: cosine similarities between negative pairs from query\n",
        "    cosine_query_distractors: cosine similarities between negative pairs\n",
        "                              from query and distractors\n",
        "    fpr: false positive rate at which to compute TPR\n",
        "  output:\n",
        "    float: threshold for given fpr\n",
        "    float: TPR at given FPR\n",
        "  '''\n",
        "  false_sims = cosine_query_neg + cosine_query_distractors\n",
        "  false_sims.sort(reverse=True)\n",
        "  num_false_pairs = len(false_sims)\n",
        "  threshold_idx = int(fpr * num_false_pairs)\n",
        "  threshold_idx = min(threshold_idx, num_false_pairs - 1)\n",
        "  threshold = false_sims[threshold_idx]\n",
        "  num_positive_pairs = len(cosine_query_pos)\n",
        "  true_positives = sum(1 for sim in cosine_query_pos if sim >= threshold)\n",
        "  tpr = true_positives / num_positive_pairs\n",
        "  return threshold, tpr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZz8_1vbFtKE"
      },
      "source": [
        "И ячейки для ее проверки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DmwpM3FH_VpR"
      },
      "outputs": [],
      "source": [
        "test_thr = []\n",
        "test_tpr = []\n",
        "for fpr in [0.5, 0.3, 0.1]:\n",
        "  x, y = compute_ir(test_cosine_query_pos, test_cosine_query_neg,\n",
        "                    test_cosine_query_distractors, fpr=fpr)\n",
        "  test_thr.append(x)\n",
        "  test_tpr.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nVYigU0jFvc9"
      },
      "outputs": [],
      "source": [
        "true_thr = [-0.011982733001947084, 0.3371426578637511, 0.701307100338029]\n",
        "assert np.allclose(np.array(test_thr), np.array(true_thr)), \"A mistake in computing threshold\"\n",
        "\n",
        "true_tpr = [0.75, 0.5, 0.5]\n",
        "assert np.allclose(np.array(test_tpr), np.array(true_tpr)), \"A mistake in computing tpr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksuMMLQOFxJ1"
      },
      "source": [
        "А в ячейке ниже вы можете посчитать TPR@FPR для датасета с лицами. Давайте, например, посчитаем для значений fpr = [0.5, 0.2, 0.1, 0.05]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhMhAza2GDL_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Результаты для реального датасета:\n",
            "TPR @ FPR=0.50: 0.7367 (Порог: 0.8480)\n",
            "TPR @ FPR=0.20: 0.4456 (Порог: 0.8892)\n",
            "TPR @ FPR=0.10: 0.2962 (Порог: 0.9061)\n",
            "TPR @ FPR=0.05: 0.1956 (Порог: 0.9181)\n"
          ]
        }
      ],
      "source": [
        "fpr_values = [0.5, 0.2, 0.1, 0.05]\n",
        "\n",
        "print(\"Результаты для реального датасета:\")\n",
        "for fpr in fpr_values:\n",
        "    threshold, tpr = compute_ir(cosine_query_pos, cosine_query_neg,\n",
        "                                cosine_query_distractors, fpr=fpr)\n",
        "    print(f\"TPR @ FPR={fpr:.2f} = {tpr:.4f} (Порог: {threshold:.4f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vcwpIx3UAw-z"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
